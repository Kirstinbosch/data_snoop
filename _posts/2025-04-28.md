---
layout: post
title: "Day 14"
description: "My new blog"
date: 2025-04-28
categories: blog
theme: "jekyll-theme-minima"
url: "https://kirstinbosch.github.io/data_snoop"
baseurl: "/data_snoop"
---

Terms: expectations of Joint Distributions, linearity of expectation, independent random variables, conditional expectations, 

When we say 
ð¸(ð‘‹âˆ£ð‘Œ)=ð¸(ð‘‹)if ð‘‹ and ð‘Œ are independent, we are not saying that the value of ð‘‹ stays the same. What we are saying is
The expected value (the average outcome) of ð‘‹ doesn't change even if you know the value of ð‘Œ. So knowing ð‘Œ tells you nothing new about ð‘‹ because ð‘‹ and ð‘Œ are independent
ð¸(ð‘‹âˆ£ð‘Œ) is still a random variable that depends on Y. But if X and y are indepndent, then ð¸(ð‘‹âˆ£ð‘Œ) becomes just a constant, it is simply E(X) - because Y gives no information about X. 

Variance:
--> the variance of a constant (non-random) quantity is zero since it has no variation.
--> Adding a constant to a random variable does not affect its variance, since we use the linearity of expectation.

